# Time Series Model Forecasting

It is straightforward to apply deep learning or classical machine learning models on time series data. At the same time, there are models and tools designed for time series forecasting specifically, but online tutorials often only contain partial information or even misleading guidance, the promotion of promising tools is not common either. Therefore, Lady H. decided to show the super power from some time series focused methods.

## Statistical Time Series Forecasting - (S)ARIMA

When it comes to time series forecasting, "ARIMA" is a popular method people often talk about, especially during data science interviews. But how many interviewees and even interviewers really used ARIMA in the work, and used well?

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/lady_heart_manga/arima_truth.png" width="971" height="384" />
</p>

Many online tutorials are misleading, either because they are missing important knowledge or contain more complex and unnecessary information. What's more, they always choose [Air Passenger data as an example][1], which is too simple to represent real world problems. One of the realities of time series forecasting is, same method applied to different datasets can lead to quite different model performance. 

So, Lady H. decided to show the ARIMA process she often applied that had been proved to be reliable on multiple time series problems. The data input will be our daily sales data:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/data_exploration/daily_sales_plot.png" width="1092" height="293" />
</p>

### Step 1: Data Exploration & Data Preprocessing

Similar to many statistical methods, ARIMA works better when the data aligns with its assumptions. It assumes the data input is a univariate stationary time series. Our sales data satisfies both assumptions, otherwise we would need to convert the data to stationary first.

Before applying ARIMA, we can plot ACF and PACF of the data first.

* ACF: It is the autocorrelation plot. 
  * Autocorrelation reflects the degree of linear dependency between ith and (i+h)th (h is the lag) time series. Autocorrelation is a value between `[-1, 1]`. Positive autocorrelation means the two time series moves towards the same direction and negative means opposite directions, 0 autocorrelation means the temporal dependency is hard to find.
  * In ACF plot, each vertical bar indicates the autocorrelation between ith ts and (i+h)th ts. Given a confidence level (such as 95%), when the bar is out of the confidence interval (the threshold lines), the autocorrelation is significant.

* PACF: It is the partial autocorrelation plot. In ACF, the autocorrelation between ith ts and (i+h)th ts can be affected by (i+1)th, (i+2)th, ..., (i+h-1)th ts too, so PACF removes the influences from these intermediate values and only checks the autocorrelation between ith ts and (i+h)th time series.
  * Lag0 always has autocorrelation as 1.

Here're the ACF and PACF plots for our daily sales data:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/acf_pacf_sales.png" width="1093" height="266" />
</p>

ðŸŒ» [Check how to plot ACF & PACF >>][2]

### Step 2: Estimate ARIMA Parameters


[1]:https://rstudio-pubs-static.s3.amazonaws.com/223827_937f502e3e89492a95404356034ea1a7.html
[2]:https://github.com/lady-h-world/My_Garden/blob/main/code/yinyang/past_forecast_arima.ipynb
