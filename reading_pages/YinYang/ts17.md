### Silverkite Template

Here's Silverkite architecture design, it looks like a complex system formed by various elements which are used for creating features and config models. However all these elements can be specified through Greykite config, in a simple way.

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_architecture.png" width="1125" height="530" />
</p>

<i>Note: Statistical Volatity Models are not covered here.</i> 

#### Config

How does Greykite config cover all these settings? Take a look at the following code:

1. `ModelComponentsParam` is where you can config feature generation and model settings.
   1. `seasonality` allows you to specify seasoanlity patterns, they will be converted to input features.
   2. `events` is where to specify special events that might be useful in forecasting, they are also in features format.
   3. `custom` is where to config models' settings.

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/notes/gk_param_multi_choices.png" width="766" height="79" />
</p>

2. `EvaluationPeriodParam` contains settings for backtesting and cross validation.
3. `MetadataParam` is where to describe your time series data input.

As shown below, to finish all the configuration, you only need to put all these settings in `ForecastConfig`:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/config_silverkite.png" width="990" height="769" />
</p>

In Lady H.'s opinion, the real selling point of Silverkite is its time series features, such as seasonality features, events features, etc. Models used in Silverkite are classical machine learning algorithms, such as linear regression, random forest, gradient boosting, etc. [Looking at Silverkite source code here][1], there's nothing special in model fitting. Same as applying classical machine learning models, it fits the model with training data and parameters.

After configuration, we can initialize a forecaster instance as simple as this:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_init.png" width="330" height="94" />
</p>

ðŸŒ» [Check detailed code of using Silverkite template >>][2]

#### Grid Search & Cross Validation

Then running the grid search with cross validation to find an optimal forecating solution:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_cv_code.png" width="1022" height="190" />
</p>

The cross validation output will show evaluation metrics values for each choice of parameter set. Which evaluation metrics to show is decided by yourself, as shown in the code above.

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_cv_output.png" width="1066" height="526" />
</p>

ðŸŒ» [Check detailed code of using Silverkite template >>][2]

#### Backtest

With the optimized model, now we can do backtest and forecast. Here's the backtest code:

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_backtest_code.png" width="216" height="62" />
</p>

As menitoned before, in Greykite, "backtest" is to predict a set of labeled testing data, that's why when configuring `EvaluationPeriodParam`  we need to specify the testing data period through `test_horizon`. In this backtest output plot, the testing data starts from "Train End Date", and we can see the comparison between the forecasted value (blue curve) as well as the actual value (orange curve).

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_backtest_plot.png" width="1449" height="324" />
</p>

Besides the plot, Greykite also output a list of evaluation metrics during the training and testing stage. To compare with ARIMA best results, we only look at R2 and MAPE here. Note that, we need to divide Greykite's MAPE by 100 in order to compare with sklearn MAPE.

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/notes/greykite_mape.png" width="766" height="79" />
</p>

Here we can see, comparing with the best ARIMA results we got, Silverkite template improved MAPE from 1.14 to 0.83 (27% decrease) and improved R2 from 0.49 to 0.76 (55% increase).

<p align="left">
<img src="https://github.com/lady-h-world/My_Garden/blob/main/images/Garden_Totem_images/forecasting/silverkite_backtest.png" width="630" height="684" />
</p>

ðŸŒ» [Check detailed code of using Silverkite template >>][2]

#### Forecast

####  Model Summary




[1]:https://github.com/linkedin/greykite/blob/7926970280a083a1457e586574327f2d21461126/greykite/algo/common/ml_models.py#L232-L259
[2]:https://github.com/lady-h-world/My_Garden/blob/main/code/yinyang/greykite_experiments/gk_forecast_tuning.ipynb
